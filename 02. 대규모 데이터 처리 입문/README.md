# 2장. 대규모 데이터 처리 입문

**메모리와 디스크, 웹 애플리케이션과 부하**

## **강의 4: 하테나 북마크의 데이터 규모**

### **대규모 데이터를 체감하기 위한 실제 사례**

- 하테나 북마크를 통해 **대규모 데이터의 실제 크기와 DB 처리 비용**을 체감해보자.
- 단순 count(*)만 해도 **3억 5천만 row**, 처리 시간이 200초 넘게 길어진다.
- 테이블 구조는 단순하지만 데이터량이 많아지면 **쿼리 시간이 폭증하는 문제가 발생한다.**

### **데이터 규모 예시**

- entry 테이블: 약 1,520만 엔트리
- bookmark 테이블: 약 4,500만 레코드
- tag 테이블: 약 5,000만 태그
- entry: 3GB, bookmark: 5.5GB, relword: 10GB, HTML: 200GB 이상
    
    → DB 전체는 수백 GB ~ 수 TB 단위가 현재는 기본이다.
    

## **강의 5: 대규모 데이터 처리의 어려운 점 (메모리와 디스크)**

### **메모리에서 모두 계산할 수 없다. But, 디스크에는 느리다.**

- 메모리 내에서 계산할 수 없다는 점이 어려운 점인 이유는 메모리에 올리지 않으면 기본적으로 디스크를
계속 읽어가면서 검색하게 된다.
- 메모리 vs 디스크 속도 차이는 **10⁵ ~ 10⁶배** 수준이다.
    
    (메모리 7.5GB/s vs 디스크 58MB/s 예시)
    

### **디스크가 느린 이유 (메모리와 비교해서)**

첫 번째 이유: 탐색 속도 차이

- 메모리는 전기적으로 값에 접근하는 매우 빠른 반도체 구조이다.
- 반면 디스크 회전하는 구조(물리적 탐색 → seek) 때문에 위치 이동에 시간이 걸린다.
- 원반 회전 속도, 헤드 이동시간, 데이터 위치 등이 탐색 속도에 영향을 미친다.
- OS도 일정 부분 데이터 페이지 캐시라는 개념으로 캐싱하지만 캐시 미스가 날 경우 마찬가지로 느리다.
- 디스크는  메모리 대비 탐색 속도가 **약 10⁵ ~ 10⁶배 느리다.**
- 최근 SSD는 이런 디스크의 단점(물리적인 한계)를 보완해서 전기 신호를 통해 데이터에 접근한다.

두 번째 이유: 전송 속도 차이 (버스 속도 차이)

- 메모리와 CPU는 매우 빠른 버스로 직접 연결된다.
- 반면 디스크와 CPU는 컨트롤러를 통한 상대적으로 좁은 대역폭을 사용한다.
- 이런 이유로 메모리 vs 디스크 전송속도 차이도 100배 이상 나게 된다.
- 최근의 SSD는 회전, 헤드 이동이 없는 전기 구조로 되어 있어 탐색 시간이 거의 0에 가깝다. 
그렇지만 버스 대역폭의 한계는 여전히 존재한다. 메모리처럼 CPU와 직접 연결되지 않기 때문에 **메모리급 성능은 아니다.**

### **I/O 병목 해결을 위한 기본 사고**

- I/O 대기 시간을 줄이는 것이 대규모 데이터 처리의 핵심이다.
- 주요 판단 기준은 다음 두 가지:
    - CPU가 일을 못하고 기다리고 있는지?
    - 디스크가 느려서 I/O가 병목인지?

### **Linux 단일 호스트 성능 분석 개요**

- 부하 관리를 위한 핵심적 명령어 정리:
    - Load Average
    - CPU 상태(sar)
    - I/O 대기(iowait)
- 병목 원인을 빠르게 파악하는 것이 중요하다.

## **강의 6: 규모 조정의 요소**

### **확장 전략: Scale-up vs Scale-out**

- **Scale-up**: 더 좋은 하드웨어로 교체 → 비용 대비 효과가 낮다.
- **Scale-out**: 서버를 여러 대로 나눠 분산 처리 → 웹 서비스에서 일반적 전략

### **CPU 부하와 I/O 부하의 차이**

- **CPU 부하 문제**는 서버 확장으로 비교적 해결 쉬움:
    - 동일한 AP 서버를 여러 대 두고 로드 밸런싱하면 해결 된다.
- **I/O 부하 문제**는 해결이 매우 어려움:
    - 보통 DB가 병목 지점이 되며, 단순히 복제만으로 해결이 불가능하다.
    - 디스크 I/O가 느리다는 특성이 본질적 원인이다.

### **웹 애플리케이션의 부하 구조(3계층)**

<img width="726" height="491" alt="image" src="https://github.com/user-attachments/assets/4a5dc095-6e89-4fc8-8c98-81f58f5bf0c1" />

1. 프록시
2. AP 서버
3. DB 서버
- AP: CPU 중심
- DB: I/O 중심 → 확장 한계가 명확

### **DB 확장성의 어려움**

- 읽기 부하는 슬레이브 DB로 분산 가능하지만 **쓰기 부하는 단일 지점**이 되기 때문에 해결 어렵다.
- 하테나 사례에서도 DB가 가장 빈번한 병목 지점이다.

## **강의 7: 대규모 데이터를 다루기 위한 기초지식**

### **대규모 데이터 다루기 3개 기본 원칙**

1. **프로그램을 작성할 때의 요령**
2. **개발 전 알아야 하는 기초지식(알고리즘/DB/OS 이해)**
3. **두 지식을 실제 프로그램 구현에 연결하는 법**

### **(1) 프로그램 작성 시 3대 금기**

대규모 데이터 처리 환경에서 다음 세 가지는 절대 피해야 한다.

1. **디스크 seek 횟수를 증가시키는 코드**
2. **메모리에 모두 올릴 수 없는 대량 데이터를 정렬/스캔하는 작업**
3. **DB에 불필요하게 반복적으로 접근하는 방식**

### **요령**

- 강력한 알고리즘 사용(Log Order)
- 데이터 읽기 횟수 최소화
- 메모리에 거의 올릴 수 있는 방식으로 설계
- DB만으로 해결하려 하지 말고 애플리케이션 레벨 검색 시스템 고려

### **(2) 대규모 데이터를 다루기 위한 3대 전제지식**

프로그램 개발 전에 반드시 알아야 할 기반 지식:

- **OS 레벨**: 메모리/디스크 구조, 캐시 동작 방식, I/O의 본질
- **RDBMS 레벨**: 인덱스, 조인, 범위 검색 비용, 읽기/쓰기 모델
- **데이터 구조 및 알고리즘**: 검색 시간 복잡도(O(log n) 등)

### **(3) 부하 확인 및 병목 파악 기초 (Load Average, sar 등)**

- Load Average → CPU Ready Queue 길이
- sar → CPU 사용률, I/O 대기 파악
- I/O 바운드인지 CPU 바운드인지 구분이 핵심
- 멀티 CPU 환경에서는 CPU별 사용률을 개별적으로 봐야 함

## 2장. 대규모 데이터 처리 입문 **요약**

- **메모리와 디스크의 극단적인 속도 차이**가 대규모 데이터 문제의 근본 원인
- 디스크 I/O는 수십만~수백만 배 느리므로, 가능한 모든 방법으로 **I/O를 최소화**해야 한다.
- DB는 읽기 부하는 분산이 가능하지만, **쓰기 부하는 분산하기 매우 어려워 병목이 되기 쉽다**.
- 규모 확장의 방향은 scale-out이며, CPU 부하는 해결 쉬우나 **I/O 부하는 근본적으로 어렵다**.
- 프로그래머는 OS·알고리즘·DB 기본기를 갖추고 있어야 대규모 데이터를 다루는 코드 작성이 가능하다.
- 부하 추적 도구(top, sar, Load Average)를 이용해 병목 원인을 빠르게 파악하는 능력이 필수이다.
