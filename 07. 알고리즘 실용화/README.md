# 7장. 알고리즘 실용화

**가까운 예로 보는 이론·연구의 실전 투입**

## **강의 19: 알고리즘과 평가**

### **데이터 규모와 계산량의 관계**

- 동일한 알고리즘이라도 **데이터 크기(n)** 가 커지면 성능 차이가 극단적으로 벌어진다.
- 예시:
    - 선형탐색(Linear Search): O(n) → 1,000만 데이터면 1,000만 회 탐색
    - 이분탐색(Binary Search): O(log n) → 같은 조건에서 24회 탐색
- 대규모 데이터에서는 작은 차이가 서비스 전체 속도에 치명적 영향을 준다.

### **좁은 의미 vs 넓은 의미의 알고리즘**

- **좁은 의미**: 입력 → 명확한 계산절차 → 출력
    
    (교과서적 알고리즘)
    
- **넓은 의미**: 서비스 전체의 설계·운영을 포함해 문제를 해결하는 접근
    
    (도메인 로직, 시스템 전체를 아우르는 사고방식)
    

### **알고리즘을 공부하는 이유**

- 컴퓨터 자원은 유한하다.
- 좋은 알고리즘 선택이 비용 절감에 직결된다.
- 새로운 문제에 대응하기 위한 필수 교양

### **Order 표기**

- O(1), O(log n), O(n), O(n log n), O(n²) …
- 대규모 데이터에서는 O(n log n)과 O(n)은 실제 체감 성능 차이가 극명해진다.
- 복잡도가 낮은 알고리즘일수록 데이터 증가에 강하다.

### **계산량과 상수항**

- Order 표기가 무시하는 **상수항** 또한 실제 구현에서는 중요
- 단순 구현이라도 상수항이 작은 경우 더 빠르기도 한다.
- 반대로 CPU 캐시, 분기예측 실패 등의 이유로 상수항이 커질 수도 있음

### **알고리즘의 실제 활용**

- 최고 성능 알고리즘이 항상 최선은 아니다.
- **고객 요구에 따라 단순한 알고리즘이 오히려 더 빠르고 관리가 쉬운 경우가 많다.**
- 하테나 북마크 Firefox 확장기능에서는 Suffix Array 기법을 실제로 적용했지만, 전처리에 상당한 시간이 필요한 단점이 있었다. 그래서 채택을 취소하고 단순한 구현으로 선회했다. 데이터량이 많은 이용자에게는 ‘속도저하는 어쩔 수 없다’는 타협을 했지만, 실제로는 전혀 문제없이 사용할 수 있었다.

### **여기서 배운 점**

- 추상적인 계산량보다 ‘**데이터 규모에 따른 실제 성능 차이**’를 체감하는 것이 중요
- 같은 데이터라도 **접근 패턴**에 따라 적합한 알고리즘이 달라진다.
- 최적화는 구현 난이도, 유지보수 비용을 포함해 판단해야 한다.

# **강의 20: 하테나 다이어리의 키워드 링크**

### **문제 배경**

- 하테나 다이어리는 사용자가 등록한 키워드를 글 본문에서 자동 링크하는 기능을 제공
- 서비스 초창기에는 키워드가 적어 정규표현식 기반으로 충분했다.
- 키워드가 수십만 개로 늘자 정규표현식 기반 방식은 **계산량 폭증 문제**가 발생했다.

### **정규표현식 → Trie → AC법(Aho–Corasick)으로의 진화**

### **1) 초기 구현: 단순 정규표현식**

- (foo|bar|baz) 형태로 모든 단어를 OR 조건으로 연결
- 키워드가 많아질수록 복잡성이 증가
- 정규표현식 엔진은 NFA 기반 → **문자 하나마다 분기 가능**, 패턴 수 * 텍스트 길이 만큼 계산 비용 증가
- 10만 개 단어 수준이 되자 성능이 버티지 못함

### **2) Trie 도입**

- 공통 접두사를 묶는 자료구조
- “abc”, “ab”, “abd” 같은 단어가 있다면 공통 접두사 ‘a’-‘b’ 아래에 정리
- 패턴 탐색 시 불필요한 비교를 줄일 수 있음
- 하지만 Trie만으로는 패턴 수가 많을 경우 다시 비효율 발생
    
    <img width="691" height="365" alt="image" src="https://github.com/user-attachments/assets/e60d5a46-abf1-419a-972f-23340d66f6ef" />
    

### **3) AC법(Aho–Corasick) 사용**

- Trie + 실패 링크(failure link)를 이용한 알고리즘
- 검색 문자열을 **한 번만 스캔(O(n))** 하면서 모든 패턴을 동시에 매칭
- 정규표현식처럼 폭발적인 계산 증가가 없음

**핵심 효과:**

- 사전의 크기(패턴 수)에 거의 영향을 받지 않는다.
- 대형 텍스트에도 매우 빠르게 매칭 가능.

<img width="687" height="410" alt="image" src="https://github.com/user-attachments/assets/486b2e70-20bb-46ed-aaf1-b3859124437b" />

### **AC법 이후 최적화 및 변천**

### **AC법 → Regexp::List 사용으로 변경**

- Perl 환경에서는 AC법 구현의 유지보수 비용이 커지자 CPAN 라이브러리 사용
- Regexp::List는 정규표현식을 구조적으로 최적화하여 OR 결합 패턴을 효율적으로 관리
- Trie 기반은 아니지만 정규표현식 트리를 최적화해 빠른 검색이 가능

### **변천 과정의 교훈**

- 처음부터 최고 성능을 적용할 필요는 없다.
- 데이터가 작을 때는 단순 방식도 충분
- 데이터 규모가 커지는 시점에 맞춰 적절한 알고리즘으로 이행하는 전략이 중요

## **강의 21: 하테나 북마크의 기사 분류**

### **문제 배경**

- 하테나 북마크는 기사 제목·본문을 보고 이를 자동으로 카테고리 분류하는 기능을 제공
- 주어진 카테고리는 “가정”, “생활”, “IT”, “경제”, “정치” 등
- 대규모 기사 데이터 4,000만 건 이상

### **베이지안 필터 기반 분류기**

### **베이지안 필터란**

- 문서 분류, 스팸 필터링 등에서 널리 사용되는 기법
- 단어 등장 확률을 기반으로 특정 카테고리에 속할 확률을 계산
- 하테나는 **나이브 베이즈(조건부 독립 가정)** 알고리즘을 사용

### **실제 적용 과정**

- 기사 수천만 건을 이용해 단어별 통계정보를 구축
- 카테고리별로 등장 확률(P(W|C))과 카테고리 자체 확률(P(C))을 계산
- 이후 새 문서가 오면 단어 기반 통계를 사용해 카테고리 판정

### **분류 엔진의 실제 구현**

- C++ 기반 서버 프로세스로 구현
- 정규표현식 기반 필터보다 1,000배 이상 빠른 처리도 가능
- Perl API → Apache Thrift RPC로 호출하도록 구성해 실서비스에 적용

### **스펠링 오류 수정 기능 구현**

### **목표**

- 사용자가 검색창에 입력한 내용이 오탈자인 경우, 가장 유사한 단어 후보를 추천

### **핵심 요소**

1. **27만 개의 하테나 키워드 사전을 기준으로 삼음**
2. **검색어와 사전 단어 간 편집거리 계산 (Levenshtein / Jaro–Winkler)**
3. **빈도 기반 점수 조합하여 최종 후보 선정**

### **편집거리 기반 접근**

- 오타: “이도 나오이” → “이토 나오야”
- 각 문자 변경 비용을 정의해 편집 거리 계산 (위 예시의 경우 편집거리 = 2)
- 1글자 차이만 나도 높은 점수

### **여기서 배운 점**

- 실제 서비스에서는 **데이터 규모와 특성**에 따라 알고리즘 선택이 달라진다.
- 계산량이 적은 알고리즘이라도 **정확도·운영 비용·데이터 구조**를 모두 고려해야 한다.
- 대규모 데이터에서는 고전 알고리즘이 그대로 적용되지 않을 수 있다.
- Trie, AC법, 베이지안 필터 등 **다양한 알고리즘을 서비스 요구에 맞게 조합**하는 것이 중요하다.

## 7장. 알고리즘 실용화 **요약**

- 대규모 데이터에서는 **계산량(Order) 차이가 현실적인 성능 차이**로 직결된다.
- 정규표현식 → Trie → AC법으로 이어지는 진화는 **데이터 증가에 따른 알고리즘 선택의 중요성**을 잘 보여준다.
- 베이지안 필터를 이용한 카테고리 분류는 **통계 기반 기계학습의 실제 적용 사례**
- 스펠링 오류 수정 기능은 **편집거리·빈도 기반 조합** 등 실전 알고리즘의 종합적인 활용 사례이다.
- **알고리즘은 서비스 운영의 실전 도구이며, 데이터 규모와 도메인 특성에 맞게 단계적으로 선택해가야 한다.**
